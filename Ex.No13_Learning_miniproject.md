# Ex.No: 10 Learning – Use Supervised Learning  
### DATE: 25/10/2025                                                                           
### REGISTER NUMBER : 212223060222
### AIM: 
To write a program to implement a Time Series Regression model using the Random Forest Regressor to predict a future meteorological variable (e.g., maximum temperature) based on historical (lagged) data, and to evaluate the model's performance using suitable metrics.
###  Algorithm:
# Time-Series Forecasting Workflow

## 1. Data Loading and Preparation
- Load the time-series dataset (simulated data is used here for reproducibility).
- Ensure the 'Date' column is in the correct datetime format.

## 2. Data Cleaning
- Convert target meteorological columns (e.g., 'TempMax', 'TempMin', 'Rainfall') to a numeric datatype.

## 3. Feature Engineering (Lagging)
- Create lagged features such as:
  - TempMax_Lag1
  - TempMin_Lag1
- These are generated by shifting the time series by one time step (t-1).
- The previous day's values serve as input features for predicting the current day's target value (y_t).

## 4. Data Preprocessing
- Drop rows containing missing values (NaN), which are primarily introduced during the lagging step.

## 5. Feature and Target Definition
- Define the feature matrix (X) using lagged variables.
- Define the target vector (y) for prediction (e.g., current TempMax).

## 6. Data Split
- Split the data into:
  - Training set: (X_train, y_train)
  - Testing set: (X_test, y_test)
- Use a time-aware split with shuffle=False to preserve chronological order.

## 7. Model Initialization and Training
- Initialize a RandomForestRegressor model.
- Train it using the training data.

## 8. Prediction
- Predict target values for the test set (X_test).

## 9. Evaluation
- Evaluate model performance using:
  - Mean Squared Error (MSE)
  - R² Score

## 10. Visualization
- Plot actual vs. predicted values over the test period.
- Assess how well the model fits and captures trends.


Stop.
### Program:

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# 1. Start & Data Loading (Using Synthetic Data for reproducibility)
# We simulate 730 days of weather data.
np.random.seed(42)
dates = pd.date_range(start='2020-01-01', periods=730, freq='D')
df = pd.DataFrame({
    'Date': dates,
    # Simulate time-dependent data (e.g., slightly warmer summers)
    'TempMax': (20 + 5 * np.sin(2 * np.pi * np.arange(730) / 365) + np.random.normal(0, 1.5, 730)),
    'TempMin': (10 + 4 * np.sin(2 * np.pi * np.arange(730) / 365) + np.random.normal(0, 1.0, 730)),
    'Rainfall': np.abs(np.random.normal(0, 3, 730))
})
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)
print("--- Initial Data Head ---")
print(df.head())
print("-" * 25)

# 2. Data Cleaning: Ensure columns are numeric
df['TempMax'] = pd.to_numeric(df['TempMax'], errors='coerce')
df['TempMin'] = pd.to_numeric(df['TempMin'], errors='coerce')
df['Rainfall'] = pd.to_numeric(df['Rainfall'], errors='coerce')

# 3. Feature Engineering: Create lagged features (t-1)
# We will predict TempMax (current day, t) using the previous day's (t-1) TempMax, TempMin, and Rainfall.
df['TempMax_Lag1'] = df['TempMax'].shift(1)
df['TempMin_Lag1'] = df['TempMin'].shift(1)
df['Rainfall_Lag1'] = df['Rainfall'].shift(1)

print("\n--- Data Head after Lagging (showing NaN in first row) ---")
print(df.head(3))
print("-" * 25)

# 4. Data Preprocessing: Drop rows with missing values (the first row after lagging)
df.dropna(inplace=True)
print(f"\nTotal rows after dropping NaN: {len(df)}")

# 5. Define the feature matrix (X) and the target vector (y)
features = ['TempMax_Lag1', 'TempMin_Lag1', 'Rainfall_Lag1']
X = df[features]
y = df['TempMax']  # Target: Current day's Max Temperature

# 6. Split the data into training and testing sets (Time-aware split: shuffle=False)
# Use the first 80% for training and the last 20% for testing.
split_point = int(len(X) * 0.8)
X_train, X_test = X[:split_point], X[split_point:]
y_train, y_test = y[:split_point], y[split_point:]

print(f"Training set size: {len(X_train)} samples")
print(f"Testing set size: {len(X_test)} samples")

# 7. Initialize and Train the RandomForestRegressor model
# Hyperparameters can be tuned, but we use a default simple setup here.
rfr_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=10)
print("\n--- Training Random Forest Regressor Model ---")
rfr_model.fit(X_train, y_train)

# 8. Predict the target values for the test set
y_pred = rfr_model.predict(X_test)

# 9. Evaluate the model's performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\n--- Model Evaluation Metrics ---")
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"R-squared (R^2) Score: {r2:.4f}")

# 10. Visualize the actual vs. predicted values
plt.figure(figsize=(14, 6))
plt.plot(y_test.index, y_test.values, label='Actual TempMax', color='#3b82f6')
plt.plot(y_test.index, y_pred, label='Predicted TempMax', linestyle='--', color='#ef4444')
plt.title('Time Series Regression Prediction (Random Forest) - Test Set')
plt.xlabel('Date')
plt.ylabel('Maximum Temperature (°C)')
plt.legend()
plt.grid(True, linestyle=':', alpha=0.6)
plt.tight_layout()
plt.show()

# 11. Stop.
```

### Output:
![Picture1](https://github.com/user-attachments/assets/0fb702a2-7709-45c2-8042-d826f6046f7b)
![Picture2](https://github.com/user-attachments/assets/44ba19ac-a0fa-4f2f-8a81-88fa2a7e0cfc)


### Result:
Thus the system was trained successfully and the prediction was carried out.
